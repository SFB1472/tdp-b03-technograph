---
title: "Commenting traces"
code-fold: true
---

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false

library(tidyverse)
library(DBI)
library(RPostgres)
library(urltools)
library(MetBrewer)
library(ggforce)
library(reactable)
library(BAMMtools)

source("../config/config-secret-local.R")
source("../config/config-graphic.R")
source("../config/config.R")


con <- dbConnect(RPostgres::Postgres(), 
                 dbname = dsn_database,
                 host = dsn_hostname, 
                 port = dsn_port,
                 user = dsn_uid, 
                 password = dsn_pwd
)


```

## Combining both approaches

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false

snippets_to_find <- read.csv("../../data/helper/24-07-12-Commenting-system-detection-patterns.csv", sep = ";")
str_snippets_to_find <- snippets_to_find %>% select(regex) %>% pull(.) %>% paste(collapse = "|")
# traces_to_search <- c(COMMENTS_IN_TAGS, str_snippets_to_find) %>% paste(collapse = "|")

get_domain_translation <- function(sphere_){
  df_return <- read_csv(file = paste0("../../data/helper/22-09-21-Top News Websites [AU - public] - ",sphere_," news.csv"), show_col_types = FALSE) %>% 
    mutate(cleaned_urls = domain(URL) %>% suffix_extract(.) %>% select(domain) %>% pull(.)) %>% 
    select(Name, cleaned_urls)
}

tag_colors <- c("iframe" = "#c969a1", "script" = "#ee8577", "form" = "#ffbb44", "div" = "#62929a", "plain text" = "#000000")

type_colors <- c("generic" = "#62929a", "snippet_list" = "#c969a1")

get_sites <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT s.crawl_date, s.site, s.sha1, s.sphere FROM sites s WHERE s.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}



get_data_traces_with_tags <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT t.site as sha1, t.trace, t.tag, t.search_type, t.search_method, t.comment, t.sphere FROM traces t WHERE t.search_topic = 'comment' AND t.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

get_data_traces <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT t.site as sha1, t.trace, t.tag, t.search_type, t.search_method, t.comment, t.sphere FROM traces t WHERE t.search_topic = 'comment' AND t.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

get_data_comment_traces <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT t.site as sha1, t.trace, t.tag, t.search_type, t.search_method, t.sphere FROM traces t WHERE t.search_topic = 'comment' AND t.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

# get_all_sites_sphere <- function(sphere_){
#   dbGetQuery(conn = con, paste0("SELECT DISTINCT s.crawl_date, s.site, COUNT(s.sha1) as sites_per_day FROM sites s WHERE s.of_interest = TRUE AND s.sphere ='", sphere_, "' GROUP BY (s.crawl_date, s.site)")) %>% 
#     filter(site %in% df_domains_to_analyse$cleaned_urls) %>% 
#     mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% #View()
#     reframe(counted_sites = sum(sites_per_day), .by = c("year_month", "site"))
#   }

print_heatmap <- function(df_data, snippet, df_retranslate_domains){
  # df_all_sites <- get_all_sites_sphere(sphere_)

  df_data %>%
    # df_snippets_in_tags_print_de %>% 
    # head(30000) %>% 
    mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% 
    reframe(counted = n(), .by = c(year_month, site, tag, search_type, comment)) %>% #View()
    left_join(., df_retranslate_domains, by = c("site" = "cleaned_urls")) %>%
        # left_join(., df_all_sites) %>%
    # rename(comment_ = comment) %>% 
    mutate(
           tag = ifelse(comment == "embedded", "src-embed", tag),
      tag = ifelse(is.na(tag), "plain text", tag)
           ) %>% #View()
    ggplot(., aes(x = year_month, y = tag, fill = search_type)) +#, alpha = normalized)) +
    geom_tile() +
    ggtitle(paste0("Searching ",snippet , " in all tags")) + 
    facet_col(vars(Name), scales = "free", space = "free") +
    scale_x_date(date_labels = "%Y", date_breaks = "2 years", limits = c(as.Date("1998-01-01"), as.Date("2021-06-01"))) +
    scale_y_discrete(position = "right") +
    scale_fill_manual(values = type_colors) +
      theme_b03_base +theme_b03_base_typo_static + theme_b03_heatmap + theme_b03_facets + theme_b03_legend_discrete + theme_b03_panel_spacing +
    # theme(axis.text.y = element_blank()) + 
    theme_b03_timeline_faceted
}

print_heatmap_ <- function(df_data, df_retranslate_domains){
  # df_all_sites <- get_all_sites_sphere(sphere_)

  df_data %>% 
    # head(30000) %>% 
    mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% 
    reframe(counted = n(), .by = c(year_month, site, search_method, search_type)) %>% #View()
    left_join(., df_retranslate_domains, by = c("site" = "cleaned_urls")) %>% 
        # left_join(., df_all_sites) %>%
    # mutate(normalized = counted/counted_sites) %>% 
    ggplot(., aes(x = year_month, y = search_type, fill = search_type)) +#, alpha = normalized)) +
    geom_tile() +
    ggtitle(paste0("Searching for traces of all types")) + 
    facet_col(vars(Name), scales = "free", space = "free") +
    scale_x_date(date_labels = "%Y", date_breaks = "2 years", limits = c(as.Date("1998-01-01"), as.Date("2021-06-01"))) +
    scale_y_discrete(position = "right") +
    scale_fill_manual(values = type_colors) +
      theme_b03_base +theme_b03_base_typo_static + theme_b03_heatmap + theme_b03_facets + theme_b03_legend_discrete + theme_b03_panel_spacing +
    # theme(axis.text.y = element_blank()) + 
    theme_b03_timeline_faceted
}

# dbDisconnect(con)

```

## Statistik: wie unterscheiden sich die Funde der verschiedenen Sprachräume?

Durch die zwei unterschiedlichen Ansätze, einmal HTML als Text zu verstehen, um darin nach Textfragmenten zu suchen und einmal HTML als die strukturierte Auszeichnungssprache, die es ist zu behandeln, eröffnet mehrere Dimensionen. 

Beide Ansätze können einander ergänzen, haben aber auch eine große Überlappung. Die folgende Tabelle zeigt die Dimensionen der Spuren, die auf den unterschiedlichen Wegen gefunden werden konnten. 

Die search-method "plain-text" gibt es nur in Kombination mit dem search-type "snippet-list". Zur Wiederholung: die Snippetliste enthält solche Fragmente, die auf Kommentarsysteme hinweisen. Diese Spuren tauchen erst auf, als Kommentaroptionen bereits Infrastruktur geworden sind und die Unternehmen, die entsprechende Software anbieten, sich mit ihren Namen in den Sourcecode des HTML und der Scripte einschreiben. 

Der zweite Ansatz, der die Struktur des Sourcecode als Ausgangspunkt nimmt, ermöglicht eine generische Suche nach Begriffen wie "Kommentar" oder "comment", was im ersten Fall nicht möglich ist. Viel zu sehr sind diese Begriffe auch Begriffe des Feldes, das untersucht wird und damit die Wahrscheinlich hoch, dass mehr traps als traces gefunden werden. 

Im zweiten Fall ist es aber möglich innerhalb der Informationen der Tags ebenfalls nach Snippets der Kommentarsysteme zu suchen. Diese Ergebnisse den Funden aus der Textsuche gegenüber zu stellen, ermöglicht es die Methoden vergleichen. Daraus ließe sich beispielweise ablesen, wenn zu wenig oder falsche Tags für den zweiten Ansatz ausgewählt wären. Das würde sich zeigen an vielen Spuren, die keine Entsprechung in den Tag-Snippetsuche haben. 

Was hier auffällt: die Snippetliste findet in den Tags viel mehr, als über die plain text Suche. Das ist ein false friend, die Spuren aus der plain-text-Suche wurden auf eine Zählung reduziert, selbst wenn es mehrere in einer Seite gegeben hätte. Bei dieser Methode liefert die Information darüber, wie oft ein Snippet gefunden wurde kaum keinen Mehrwert. Im Vergleich der Seiten untereinander, kann eine veränderte Anzahl der Spuren aber auch hier ein Hinweis auf eine Veränderung in der Seite sein. 

Die Untersuchung der Spuren innerhalb der Tags sind dieser Analyse überlegen, denn daraus lassen sich u.a. Rückschlüsse auf Programmierpraktiken schließen und diese Kenntnis kann wiederum hilfreich sein für den Übersetzungprozess den Wandel von Kommentaroptionen zu visualisieren. 


```{r}

df_stats_1 <- dbGetQuery(conn = con, "SELECT t.sphere, t.search_type, t.search_method, COUNT(*) as counted FROM traces t GROUP BY (t.sphere, t.search_method, t.search_type)")

reactable(df_stats_1, defaultSorted = c("sphere", "search_type"))

```

## Statistik: in welchen Elementen wurden die Spuren gefunden

Die Beantwortung der Frage zielt hier noch auf die Struktur der HTML-Elemente. Tags dienen zur Strukturierung der Seite und ermöglichen so eine zielgerichtetere Ausrichtung der Methode. Tags selbst sind aber auch Informationsträger, sie können eine ganze Reihe Eigenschaften aufweisen, die Spuren auf Kommentaroptionen enthalten. 

Solche Eigenschaften werden in sog. Attribut:Value Kombinationen notiert, z.b. `<div width = "100%" disqus-id = "1234">`. Dieses div tag enthält eine Attribut-Wert-Kombination, die besagt, dass dieses Element eine Breite von 100% in der Webseite einnehmen soll. Außerdem gibt es ein Attribut mit dem Namen disqus-id. Der Wert dieser Kombination ist für die Forschung irrelevant, das Attribut aber wichtig.
Andere Websiten könnten die gleiche Information wie folgt kodieren `<div width = "100%" data = "disqus-id-1234">`. An der Funktionalität ändern das nichts, unterschiedliche Webseiten-Entwickler implementieren die notwendige Information auf verschiedene Weise. 

Das Beispiel zeigt unterschiedliche Praktiken des Programmierens, für die Recherche nach den Spuren der Kommentaroptionen zeigt es, dass alle Datenfelder für die Auswertung relevant sind. Zunächst werden die Tag identifiziert, daraus die Attribut-Wert-Kombinationen entnommen und in den resultierenden Spalten nach Spuren gesucht. Die folgenden Tabellen fächern die obigen Informationen noch etwas weiter auf und zeigen welche Teile eines Tags Spurenträger sind. 

Warum ist diese Detailtiefe wichtig? Um von hier aus weiter in Richtung Forschungsfrage zu arbeiten, ist es relevant zu wissen, ob sich über die unterschiedlichen Sprachräume verschiedene Praktiken des Programmierens zeigen, die dann nicht auf gleiche Weise übersetzt werden können, wenn es darum geht Veränderungen ausfindig zu machen. 

Zum oben formulieren Rechercheauftrag: vielleicht ein Ansatzpunkt zu schauen, ob die Snippets in plain-text alle unique sind, aber in den tags obviously not. 

Steht in der Spalte `comment` "embedded", wurde die Spur in einem eingebetteten Script-Tag gefunden.  

```{r}

df_stats_comment <- dbGetQuery(conn = con, paste0("SELECT t.sphere, t.search_type, t.search_method, t.comment, COUNT(*) as counted FROM traces t  GROUP BY (t.sphere, t.search_method, t.search_type, t.comment)"))

orange_pal <- function(x) rgb(colorRamp(c("#eff4f5", "#62929a"))(x), maxColorValue = 255)


```


::: panel-tabset

### German

```{r}

SPHERE_FOR_TABSET <- "German"
df_print <- df_stats_comment %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_comment$counted)) / (max(df_stats_comment$counted) - min(df_stats_comment$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ))

```

### International

```{r}
SPHERE_FOR_TABSET <- "World"

df_print <- df_stats_comment %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_comment$counted)) / (max(df_stats_comment$counted) - min(df_stats_comment$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ))
```

### Dutch

```{r}
SPHERE_FOR_TABSET <- "Dutch"

df_print <- df_stats_comment %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_comment$counted)) / (max(df_stats_comment$counted) - min(df_stats_comment$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ))

```

:::

## Statistik: Kleinteiligste Darstellung

Diese Darstellung ist interessant für die weitere Verarbeitung der Daten. Da wird es notwendig die Spuren von individuellen Markern, wie beispielsweise IDs, die auf konkrete User, Kommentare oder Artikel hinweisen zu abstrahieren. Notwendig ist das beispielweise für die Hashes, die schon verschiedentlich erwähnt wurden. Je individueller die Spuren, desto störanfälliger die Hashes, deren Aufgabe es sein soll Vergleichbarkeit herzustellen und möglichst Praktiken des Kommentieren zu kodieren. Aber vielleicht ist das auch noch nicht zu Ende gedacht. 

Note to future Mika: vielleicht irgendwo mal die zentrale Rolle von ids erklären

```{r}

df_stats_tags <- dbGetQuery(conn = con, paste0("SELECT t.sphere, t.search_type, t.search_method, t.comment, t.tag, COUNT(*) as counted FROM traces t  GROUP BY (t.sphere, t.search_method, t.search_type, t.comment, t.tag)"))


```


::: panel-tabset


### German

```{r}
SPHERE_FOR_TABSET <- "German"

df_print <- df_stats_tags %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_tags$counted)) / (max(df_stats_tags$counted) - min(df_stats_tags$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ), defaultPageSize = 12)

```

### International

```{r}
SPHERE_FOR_TABSET <- "World"

df_print <- df_stats_tags %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_tags$counted)) / (max(df_stats_tags$counted) - min(df_stats_tags$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ), defaultPageSize = 14)
# reactable(df_stats_world %>% arrange(search_type), 

```

### Dutch

```{r}
SPHERE_FOR_TABSET <- "Dutch"

df_print <- df_stats_tags %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  arrange(search_type) %>% 
  select(-sphere)

reactable(df_print, columns = list(
    counted = colDef(
      style = function(value) {
        normalized <- (value - min(df_stats_tags$counted)) / (max(df_stats_tags$counted) - min(df_stats_tags$counted))
        color <- orange_pal(normalized)
        list(background = color)
      }
    )
  ), defaultPageSize = 11)

```

:::

## Zeitverlauf: methodische Spuren

```{r}
#| fig-height: 9
#| fig-width: 10

get_plot <- function(sphere_){
# sphere_ <- "World"
  df_stats_tags <- dbGetQuery(conn = con, paste0("SELECT s.crawl_date, t.sphere, t.search_type, t.search_method, t.comment, t.tag FROM traces t LEFT JOIN sites s ON t.site = s.sha1 WHERE t.sphere = '",sphere_,"'"))
  
  
  df_print_ <- df_stats_tags %>% 
    mutate(group = cur_group_id(), .by = c(search_type, search_method, comment, tag)) %>% #View()
    mutate(year_cleaned = year(crawl_date), 
           title = paste(search_type, search_method, comment, tag, sep = "-")) %>% 
    reframe(counted = n(), .by = c(year_cleaned, search_type, search_method, comment, tag, group, title)) 
  
  breaks <- getJenksBreaks(df_print_$counted, 5)
  
  df_print <- df_print_ %>% 
    mutate(color_breaks = cut(counted, breaks = breaks, include.lowest = TRUE, right = FALSE, labels = FALSE),
           color_labels = cut(counted, breaks = breaks, include.lowest = TRUE))# %>% as.character()) #%>% View()
  
  color_labels <- breaks[-5]
  
  ggplot(df_print, aes(x = year_cleaned, y = 1, fill= color_breaks)) +
    geom_tile() +
    facet_col(vars(title), scales = "free_y", space = "free") +
    scale_x_continuous(expand = c(0,NA), limits = c(1997,2021)) +
    # scale_fill_manual(values = met.brewer("Hokusai2"), na.value = "grey90", name = "number of traces found" ) +
    scale_fill_gradientn(colors = met.brewer("Hokusai2", type="continuous"), na.value = "grey90", labels = color_labels, name = "number of websites available" ) +
    guides(fill = guide_colorbar(title.position = "top", barwidth = unit(20, "lines"), barheight = unit(.5, "lines"))) +
    theme_b03_base + 
    theme_b03_base_typo_static +
    theme_b03_heatmap +
    theme_b03_facets +
    theme_b03_legend_discrete +
    theme_b03_panel_spacing +
    theme(axis.text.y = element_blank()
          )
}
```


:::panel-tabset

### German

```{r}
#| fig-height: 8
#| fig-width: 10
#| warning: false

get_plot("German")

```

### International

```{r}
#| fig-height: 9
#| fig-width: 10
#| warning: false

get_plot("World")

# df_world <- dbGetQuery(conn = con, paste0("SELECT s.crawl_date, t.sphere, t.search_type, t.search_method, t.site, t.trace FROM traces t LEFT JOIN sites s ON t.site = s.sha1 WHERE t.sphere = 'World' AND t.search_method = 'plain_text'"))

```

### Dutch

```{r}
#| fig-height: 7
#| fig-width: 10
#| warning: false

get_plot("Dutch")

```

:::



## Vergleich der unterschiedlichen Ansätze auf Unternehmensebene

Ein stichprobenartiger Vergleich der Spuren der verschiedenen Ansätze zeigt interessante "Lücken" auf. 

Im Fall der SZ gibt es beispielsweise 13 Seiten, in denen das Snippet "disqus_thread" in der Textsuche gefunden wurde, aber nicht in den Tags. In diesem Fall wurde im eingebetteten CSS der Seite eine Klasse mit diesem Namen definiert. Sie kommt aber in der Seite nicht zum Einsatz. Diese Spur kann man deuten als einen Überrest eines Tests: vorübergehend wurde hier zusätzliche Styles definiert, die in den Seiten noch zu finden sind, die Funktionalität aber nicht. 

Bei der Welt gibt es Spuren auf Disqus in einem Link-Tag (`<a>`), diese habe ich nicht extra geparst. Meine (womöglich falsche) Annahme, dass alle Verlinkungen einen Bezug zu div-Tags haben würden geht hier schief. Ein span-Tag trägt hier noch eine Information "commentCount". 

Frankfurter Rundschau auch in a- und span-tags Spuren auf disqus. 

Das Argument für das Parsen der Tags lautet ja, dass es die Perspektive weitet. Diese Beobachtung führt zu einer weiteren Differenzierung der Spuren: Das Auffinden einer nicht verwendeten CSS-Klasse ohne Verwendung ist noch abstrakter, als das ein div-Tag, das zwar noch "disqus-threat" heißt, aber keinerlei Daten der Kommentare und Interaktionsmöglichkeiten mehr enthält. Einzig die Tatsache, dass es einige Funde in Link-tags gibt, die nicht einzeln geparst wurden, gibt zu denken, ob diese nicht noch zusätzlich extrahiert werden sollten.


## Grafik zu allen Kommentarspuren in dem Datensatz

Wie die Grafik zu lesen ist: Die Grafik verbindet beide Ansätze miteinander. Die Liste der vordefinierten Snippets wird hier auf die Tags angewendet. Das bringt einen enormen Vorteil für das weitere Vorgehen, denn über die Funde der Snippets in der Struktur des HTML, können diese Spuren auch für ein potentielles machine learning verwendet werden.

Zwischen den beiden Datensätzen gibt es (zum Glück) eine große Überlappung. Finden sich die Spuren aus der plain-text-suche innerhalb von Tags, werden sie in der Farbe des Tags gezeichnet. Befinden sie sich außerhalb, werden sie schwarz eingezeichnet.

Darstellung sehr methodisch, interessanter: welche Spuren werden wann gefunden? Also, wenn Snippets gefunden werden, welche? Die generischen ... hm, wenn sich die schreibweise ändert, sagt das auch was, wenn sich tags ändern auch. Was wäre hier eine gute darstellung?

::: panel-tabset

### German

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false
#| fig-height: 65
#| fig-width: 10

df_retranslate_domains_de <- get_domain_translation("German")
df_sites_de <- get_sites("German")
df_snippets_de <- get_data_traces("German") %>% left_join(., df_sites_de)

# df_snippets_de %>% select(trace, tag, search_type, search_method, comment) %>% distinct() %>% View()
findings_tags <- df_snippets_de %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_de <- df_snippets_de %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags$sha1)

df_snippets_in_tags_print_de <- df_snippets_de %>% 
  bind_rows(., non_overlapping_findings_sites_de)

print_heatmap(df_snippets_in_tags_print_de, "snippets of commenting systems", df_retranslate_domains_de)

```

### International

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 65
#| fig-width: 10

df_retranslate_domains_world <- get_domain_translation("World")
df_sites_world <- get_sites("World")
df_snippets_world <- get_data_traces("World") %>% left_join(., df_sites_world)

findings_tags_world <- df_snippets_world %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_world <- df_snippets_world %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags_world$sha1)

df_snippets_in_tags_print_world <- df_snippets_world %>% 
  bind_rows(., non_overlapping_findings_sites_world)

print_heatmap(df_snippets_in_tags_print_world, "snippets of commenting systems", df_retranslate_domains_world)
```

### Dutch



```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 65
#| fig-width: 10

df_retranslate_domains_nl <- get_domain_translation("Dutch")
df_sites_nl <- get_sites("Dutch")
df_snippets_nl <- get_data_traces("Dutch") %>% left_join(., df_sites_nl)

findings_tags_nl <- df_snippets_nl %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_nl <- df_snippets_nl %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags$sha1)

df_snippets_in_tags_print_nl <- df_snippets_nl %>% 
  bind_rows(., non_overlapping_findings_sites_nl)

print_heatmap(df_snippets_in_tags_print_nl, "snippets of commenting systems", df_retranslate_domains_nl)

```

:::


## Häufigkeitsverteilung: Wie viele Spuren pro Seite

```{r}

df_stats_2 <- dbGetQuery(conn = con, "SELECT t.sphere, t.site, search_method, COUNT(*) as counted FROM traces t GROUP BY (t.sphere, t.site, t.search_method)")

```

Kommt mir so unsinnig vor, wenn ich auf die Fragmente schaue

```{r}
SPHERE_FOR_TABSET <- "German"

df_stats_2 %>% 
  filter(sphere == SPHERE_FOR_TABSET) %>% 
  ggplot(aes(x = counted)) +
  geom_bar() +
  scale_x_continuous(limits = c(0, 250))+
  facet_wrap(~search_method)

```



## Vergleich der unterschiedlichen Methoden

to do


```{r}

get_plot_sippet_generic <- function(sphere_){
  df_stats_tags <- dbGetQuery(conn = con, paste0("SELECT s.crawl_date, t.sphere, t.search_type, t.search_method FROM traces t LEFT JOIN sites s ON t.site = s.sha1 WHERE t.sphere = '",sphere_,"'"))
  
  df_print_ <- df_stats_tags %>% 
    mutate(year_cleaned = year(crawl_date),
           title = paste0(search_type,"-", search_method)) %>% 
    reframe(counted = n(), .by = c(year_cleaned, search_type, search_method, title))  
    
  
  ggplot(df_print_, aes(x = year_cleaned, y = title)) +
    geom_tile() +
    scale_x_continuous(expand = c(0,NA), limits = c(1997,2021)) +
    # scale_fill_manual(values = met.brewer("Hokusai2"), na.value = "grey90", name = "number of traces found" ) +
    # scale_fill_gradientn(colors = met.brewer("Hokusai2", type="continuous"), na.value = "grey90", labels = color_labels, name = "number of websites available" ) +
    # guides(fill = guide_colorbar(title.position = "top", barwidth = unit(20, "lines"), barheight = unit(.5, "lines"))) +
    theme_b03_base + 
    theme_b03_base_typo_static +
    theme_b03_heatmap +
    theme_b03_facets +
    theme_b03_legend_discrete +
    theme_b03_panel_spacing

}
```


::: panel-tabset

### German

```{r}
#| fig-height: 2
#| fig-width: 10

get_plot_sippet_generic("German")

```

### International

```{r}
#| fig-height: 4
#| fig-width: 10

get_plot_sippet_generic("World")
```

### Dutch

```{r}
#| fig-height: 4
#| fig-width: 10

get_plot_sippet_generic("Dutch")
```

:::


## Fazit

Die zuverlässigste Quelle Spuren auf Kommentaroptionen zu finden sind in die Seite eingebettete Script-Tags. Das war überraschend, vor allem angesichts dessen, dass diese lange außen vor gelassen wurde. 


## random Notes
Schönere Tabellendarstellung in quarto-Dokumenten: https://glin.github.io/reactable/articles/examples.html

