---
title: "Commenting traces"

---

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false

library(tidyverse)
library(DBI)
library(RPostgres)
library(urltools)
library(MetBrewer)
library(ggforce)

source("../config/config-secret-local.R")
source("../config/config-graphic.R")
source("../config/config.R")


con <- dbConnect(RPostgres::Postgres(), 
                 dbname = dsn_database,
                 host = dsn_hostname, 
                 port = dsn_port,
                 user = dsn_uid, 
                 password = dsn_pwd
)


```

# Combining both approaches

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false

snippets_to_find <- read.csv("../../data/helper/24-07-12-Commenting-system-detection-patterns.csv", sep = ";")
str_snippets_to_find <- snippets_to_find %>% select(regex) %>% pull(.) %>% paste(collapse = "|")
# traces_to_search <- c(COMMENTS_IN_TAGS, str_snippets_to_find) %>% paste(collapse = "|")

get_domain_translation <- function(sphere_){
  df_return <- read_csv(file = paste0("../../data/helper/22-09-21-Top News Websites [AU - public] - ",sphere_," news.csv"), show_col_types = FALSE) %>% 
    mutate(cleaned_urls = domain(URL) %>% suffix_extract(.) %>% select(domain) %>% pull(.)) %>% 
    select(Name, cleaned_urls)
}

tag_colors <- c("iframe" = "#c969a1", "script" = "#ee8577", "form" = "#ffbb44", "div" = "#62929a", "plain text" = "#000000")

type_colors <- c("generic" = "#62929a", "snippet_list" = "#c969a1")

get_sites <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT s.crawl_date, s.site, s.sha1, s.sphere FROM sites s WHERE s.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

get_data_traces_with_tags <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT t.site as sha1, t.trace, t.tag, t.search_type, t.search_method, t.comment, t.sphere FROM traces t WHERE t.search_topic = 'comment' AND t.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

get_data_traces <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT s.site, s.sha1, s.crawl_date, t.search_method, t.search_type, t.trace FROM sites s INNER JOIN traces t ON s.sha1 = t.site WHERE t.search_topic='comment' AND t.sphere ='", sphere_,"' AND s.of_interest = TRUE"), check_interrupts = TRUE)
}

get_data_comment_traces <- function(sphere_){
  df <- dbGetQuery(conn = con, paste0("SELECT DISTINCT t.site as sha1, t.trace, t.tag, t.search_type, t.search_method, t.sphere FROM traces t WHERE t.search_topic = 'comment' AND t.sphere = '",sphere_,"'"), check_interrupts = TRUE)
}

# get_all_sites_sphere <- function(sphere_){
#   dbGetQuery(conn = con, paste0("SELECT DISTINCT s.crawl_date, s.site, COUNT(s.sha1) as sites_per_day FROM sites s WHERE s.of_interest = TRUE AND s.sphere ='", sphere_, "' GROUP BY (s.crawl_date, s.site)")) %>% 
#     filter(site %in% df_domains_to_analyse$cleaned_urls) %>% 
#     mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% #View()
#     reframe(counted_sites = sum(sites_per_day), .by = c("year_month", "site"))
#   }

print_heatmap <- function(df_data, snippet, df_retranslate_domains){
  # df_all_sites <- get_all_sites_sphere(sphere_)

  df_data %>% 
    # head(30000) %>% 
    mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% 
    reframe(counted = n(), .by = c(year_month, site, tag, search_type)) %>% #View()
    left_join(., df_retranslate_domains, by = c("site" = "cleaned_urls")) %>% 
        # left_join(., df_all_sites) %>%
    mutate(tag = ifelse(is.na(tag), "plain text", tag)) %>%
    ggplot(., aes(x = year_month, y = tag, fill = search_type)) +#, alpha = normalized)) +
    geom_tile() +
    ggtitle(paste0("Searching ",snippet , " in all tags")) + 
    facet_col(vars(Name), scales = "free", space = "free") +
    scale_x_date(date_labels = "%Y", date_breaks = "2 years", limits = c(as.Date("1998-01-01"), as.Date("2021-06-01"))) +
    scale_y_discrete(position = "right") +
    scale_fill_manual(values = type_colors) +
      theme_b03_base +theme_b03_base_typo_static + theme_b03_heatmap + theme_b03_facets + theme_b03_legend_discrete + theme_b03_panel_spacing +
    # theme(axis.text.y = element_blank()) + 
    theme_b03_timeline_faceted
}

print_heatmap_ <- function(df_data, df_retranslate_domains){
  # df_all_sites <- get_all_sites_sphere(sphere_)

  df_data %>% 
    # head(30000) %>% 
    mutate(year_month = paste0(year(crawl_date), "-", month(crawl_date), "-01") %>% ymd()) %>% 
    reframe(counted = n(), .by = c(year_month, site, search_method, search_type)) %>% #View()
    left_join(., df_retranslate_domains, by = c("site" = "cleaned_urls")) %>% 
        # left_join(., df_all_sites) %>%
    # mutate(normalized = counted/counted_sites) %>% 
    ggplot(., aes(x = year_month, y = search_type, fill = search_type)) +#, alpha = normalized)) +
    geom_tile() +
    ggtitle(paste0("Searching for traces of all types")) + 
    facet_col(vars(Name), scales = "free", space = "free") +
    scale_x_date(date_labels = "%Y", date_breaks = "2 years", limits = c(as.Date("1998-01-01"), as.Date("2021-06-01"))) +
    scale_y_discrete(position = "right") +
    scale_fill_manual(values = type_colors) +
      theme_b03_base +theme_b03_base_typo_static + theme_b03_heatmap + theme_b03_facets + theme_b03_legend_discrete + theme_b03_panel_spacing +
    # theme(axis.text.y = element_blank()) + 
    theme_b03_timeline_faceted
}

# dbDisconnect(con)

```

## Snippets found - plain text and tags


Ein stichprobenartiger Vergleich der Spuren der verschiedenen Ansätze zeigt interessante "Lücken" auf. Generell gibt es mehr Funde wenn HTML als Text verstanden wird. 

Im Fall der SZ gibt es beispielsweise 13 Seiten, in denen das Snippet "disqus_thread" in der Textsuche gefunden wurde, aber nicht in den Tags. In diesem Fall wurde im eingebetteten CSS der Seite eine Klasse mit diesem Namen definiert. Sie kommt aber in der Seite nicht zum Einsatz. Diese Spur kann man deuten als einen Überrest eines Tests: vorübergehend wurde hier zusätzliche Styles definiert, die in den Seiten noch zu finden sind, die Funktionalität aber nicht. 

Gigya wird nur über die plain-text-Suche gefunden. Alle Spuren darauf sind in einem Script-Tag direkt in die Seiten geschrieben. Auch gibt es hiervon nur eine Handvoll Seiten. 

Bei der Welt gibt es Spuren auf Disqus in einem Link-Tag, diese habe ich nicht extra geparst. Meine (womöglich falsche) Annahme, dass alle Verlinkungen einen Bezug zu div-Tags haben würden geht hier schief. Ein span-Tag trägt hier noch eine Information "commentCount". 

Frankfurter Rundschau auch in a- und span-tags Spuren auf disqus. 

Grobes Fazit: in dem gröberen Ansatz der Textsuche im HTML finden sich mehr Spuren auf Kommentarsysteme. Das liegt daran, dass hier auch Bereiche durchsucht werden, die bei der Selektion der Tags außen vor bleiben. Was eine interessante Perspektive ist, denn das Argument für das Parsen der Tags lautet ja, dass es die Perspektive weitet. Diese Beobachtung führt zu einer weiteren Differenzierung der Spuren. Das Auffinden einer nicht verwendeten CSS-Klasse ohne Verwendung ist noch abstrakter, als das ein div-Tag, das zwar noch "disqus-threat" heißt, aber keinerlei Daten der Kommentare und Interaktionsmöglichkeiten mehr enthält. Einzig die Tatsache, dass es einige Funde in Link-tags gibt, die nicht einzeln geparst wurden, gibt zu denken, ob diese nicht noch zusätzlich extrahiert werden sollten.

Wie die Grafik zu lesen ist: Die Grafik verbindet beide Ansätze miteinander. Die Liste der vordefinierten Snippets wird hier auf die Tags angewendet. Das bringt einen enormen Vorteil für das weitere Vorgehen, denn über die Funde der Snippets in der Struktur des HTML, können diese Spuren auch für das machine learning verwendet werden.

Zwischen den beiden Datensätzen gibt es (zum Glück) eine große Überlappung. Finden sich die Spuren aus der plain-text-suche innerhalb von Tags, werden sie in der Farbe des Tags gezeichnet. Befinden sie sich außerhalb, werden sie schwarz eingezeichnet.

::: panel-tabset

### German

```{r}
#| echo: false
#| warning: false
#| error: false
#| message: false
#| fig-height: 75
#| fig-width: 10

df_retranslate_domains_de <- get_domain_translation("German")
df_sites_de <- get_sites("German")
df_snippets_de <- get_data_traces_with_tags("German") %>% left_join(., df_sites_de) #%>% View()

# df_snippets_de %>% select(trace, tag, search_type, search_method, comment) %>% distinct() %>% View()

findings_tags <- df_snippets_de %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_de <- df_snippets_de %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags$sha1)

df_snippets_in_tags_print_de <- df_snippets_de %>% 
  bind_rows(., non_overlapping_findings_sites_de)

print_heatmap(df_snippets_in_tags_print_de, "snippets of commenting systems", df_retranslate_domains_de)

```

### International

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 55
#| fig-width: 10

df_retranslate_domains_world <- get_domain_translation("World")
df_sites_world <- get_sites("World")
df_snippets_world <- get_data_traces_with_tags("World") %>% left_join(., df_sites_world)

findings_tags_world <- df_snippets_world %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_world <- df_snippets_world %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags_world$sha1)

df_snippets_in_tags_print_world <- df_snippets_world %>% 
  bind_rows(., non_overlapping_findings_sites_world)

print_heatmap(df_snippets_in_tags_print_world, "snippets of commenting systems", df_retranslate_domains_world)
```

### Dutch



```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 45
#| fig-width: 10

df_retranslate_domains_nl <- get_domain_translation("Dutch")
df_sites_nl <- get_sites("Dutch")
df_snippets_nl <- get_data_traces_with_tags("Dutch") %>% left_join(., df_sites_nl)

findings_tags_nl <- df_snippets_nl %>% filter(search_method == "tag", search_type == "snippet_list") 

non_overlapping_findings_sites_nl <- df_snippets_nl %>% filter(search_method == "plain_text", search_type == "snippet_list") %>% filter(!sha1 %in% findings_tags$sha1)

df_snippets_in_tags_print_nl <- df_snippets_nl %>% 
  bind_rows(., non_overlapping_findings_sites_nl)

print_heatmap(df_snippets_in_tags_print_nl, "snippets of commenting systems", df_retranslate_domains_nl)

```

:::


## Traces of "comment|komment" found


::: panel-tabset

### German

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 42
#| fig-width: 10

df_comment_traces_de <- get_data_comment_traces("German") %>% left_join(., df_sites_de)
print_heatmap(df_comment_traces_de, "Comment traces",df_retranslate_domains_de)

```

### International

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 50
#| fig-width: 10

df_comment_traces_world <- get_data_comment_traces("World")%>% left_join(., df_sites_world)
print_heatmap(df_comment_traces_world, "Comment traces",df_retranslate_domains_world)

```

### Dutch

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 40
#| fig-width: 10

df_comment_traces_nl <- get_data_comment_traces("Dutch") %>% left_join(., df_sites_nl)
print_heatmap(df_comment_traces_nl, "Comment traces",df_retranslate_domains_nl)

```

:::

## Übersicht Kommentarspuren

```{r}
#| echo: false
#| warning: false
#| error: false
#| fig-height: 42
#| fig-width: 10


# print_data <- get_data_traces("German") %>% filter(trace != "fyRe")
# print_heatmap_(print_data, df_retranslate_domains_de)


```



